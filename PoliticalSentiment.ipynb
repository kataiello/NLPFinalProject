{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Need to calculate the following:\n",
    "Classifier:\n",
    "P(s|T) = (P(s)*P(T|s))/P(T)\n",
    "T is the text of the tweet and s is the sentiment\n",
    "\n",
    "P(T|s) = P(G|s) = product(for every g in G)(P(g|s))\n",
    "Where G is the set of n-grams and g is an individual n-gram\n",
    "Calculate P(g|s) using +1 for 0 values\n",
    "\n",
    "Calculate P(T) for all T\n",
    "Then add all g to sets s with counts\n",
    "'''\n",
    "\n",
    "\n",
    "#haven't collected corpus yet, assume this will be filled in\n",
    "#Load processed tweets here\n",
    "with open('hillProcessed.txt') as f:\n",
    "    hillProcessed = f.read()\n",
    "hillTweets = hillProcessed.split('\\n')\n",
    "\n",
    "with open('trumpProcessed.txt') as f:\n",
    "    trumpProcessed = f.read()\n",
    "trumpTweets = trumpProcessed.split('\\n')\n",
    "\n",
    "#Load tokens files for bigrams\n",
    "with open('hill_tokens.txt') as f:\n",
    "    hillTokensFile = f.read()\n",
    "    \n",
    "hillTokens = hillTokensFile.strip().split('\\n')\n",
    "\n",
    "with open('trump_tokens.txt') as f:\n",
    "    trumpTokensFile = f.read()\n",
    "    \n",
    "trumpTokens = trumpTokensFile.strip().split('\\n')\n",
    "\n",
    "#Load counts of types here as hillTypes and trumpTypes\n",
    "with open('hill_counts.txt') as f:\n",
    "    hCountsFile = f.read()\n",
    "hCounts = hCountsFile.strip().split('\\n')\n",
    "hillTypes = {}\n",
    "for i in range (len(hCounts)):\n",
    "    hCounts[i] = hCounts[i].lstrip()\n",
    "    hillTypes[hCounts[i].split(' ')[1]] = int(hCounts[i].split(' ')[0]) \n",
    "    \n",
    "with open('hill_counts.txt') as f:\n",
    "    hCountsFile = f.read()\n",
    "hCounts = hCountsFile.strip().split('\\n')\n",
    "hillTypes = {}\n",
    "for i in range (len(hCounts)):\n",
    "    hCounts[i] = hCounts[i].lstrip()\n",
    "    hillTypes[hCounts[i].split(' ')[1]] = int(hCounts[i].split(' ')[0]) \n",
    "    \n",
    "with open('trump_counts.txt') as f:\n",
    "    tCountsFile = f.read()\n",
    "tCounts = tCountsFile.strip().split('\\n')\n",
    "trumpTypes = {}\n",
    "for i in range (len(tCounts)):\n",
    "    tCounts[i] = tCounts[i].lstrip()\n",
    "    trumpTypes[tCounts[i].split(' ')[1]] = int(tCounts[i].split(' ')[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def runAnalysis(testFile):\n",
    "    with open(testFile) as f:\n",
    "        testText = f.read()\n",
    "    testLines = testText.split('\\n')\n",
    "    testTweets = []\n",
    "    \n",
    "    for line in testLines:\n",
    "        #remove @usernames, #hashtags, RTs, links\n",
    "        result = re.sub(r\"(?:@\\S*|#\\S*|RT|http\\S*)\", \"\", line)\n",
    "        #set all letters to lowercase\n",
    "        result = result.lower()\n",
    "        #substitute all punctuation with a space\n",
    "        result = re.sub(r\"[^\\w\\s]\",' ',result)\n",
    "        result = re.sub(' +', ' ', result)\n",
    "        result = result.strip()\n",
    "        if result != '':\n",
    "            result = \"<start> \" + result + \" <end>\"\n",
    "            testTweets.append(result)\n",
    "        \n",
    "    totalHill = numpy.float32(0.0)\n",
    "    totalTrump = numpy.float32(0.0)\n",
    "    for tweet in testTweets:\n",
    "        pHill, pTrump = classify(tweet)\n",
    "        totalHill += pHill\n",
    "        totalTrump += pTrump\n",
    "        print (\"For tweet: {} \\nProbability of supporting \\n Hillary Clinton: {} \\n Donald Trump: {}\".format(tweet, pHill, pTrump))\n",
    "    proHill = totalHill / (totalHill + totalTrump)\n",
    "    proTrump = totalTrump / (totalHill + totalTrump)\n",
    "    print(\"% supporting Hillary Clinton: {} \\n% supporting Donald Trump: {}\".format(proHill, proTrump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for every word, add it to the dictionary in this format:\n",
    "#key is the word, value is another dictionary\n",
    "    #within each subdictionary, have the following word as the key\n",
    "    #and the number of times it follows as the value\n",
    "\n",
    "def generateBigramsDict():\n",
    "    #make a bigrams dictionary for both and each candidate\n",
    "    bigrams = {}\n",
    "    hillBigrams = {}\n",
    "    trumpBigrams = {}\n",
    "    #Add all Hillary positive bigrams to both hillBigrams and bigrams\n",
    "    for i in range(len(hillTokens) - 1):\n",
    "        #if the word already exists\n",
    "        if hillTokens[i] in hillBigrams:\n",
    "            #if the following word already exists\n",
    "            if hillTokens[i+1] in hillBigrams[hillTokens[i]]:\n",
    "                #add 1 to the number of occurences\n",
    "                hillBigrams[hillTokens[i]][hillTokens[i+1]] += 1\n",
    "                bigrams[hillTokens[i]][hillTokens[i+1]] += 1\n",
    "            #add it to the subdictionary of hill\n",
    "            else:\n",
    "                hillBigrams[hillTokens[i]][hillTokens[i+1]] = 1\n",
    "                bigrams[hillTokens[i]][hillTokens[i+1]] = 1\n",
    "        #the word does not exist yet in hillBigrams\n",
    "        else:\n",
    "            #initialize a new subdictionary and add the first bigram\n",
    "            hillBigrams[hillTokens[i]] = {hillTokens[i+1]: 1}\n",
    "            bigrams[hillTokens[i]] = {hillTokens[i+1]: 1}\n",
    "\n",
    "    #Add all Trump positive bigrams to both trumpBigrams and bigrams\n",
    "    for i in range(len(trumpTokens) - 1):\n",
    "        #if the word already exists\n",
    "        if trumpTokens[i] in trumpBigrams:\n",
    "            #if the following word already exists\n",
    "            if trumpTokens[i+1] in trumpBigrams[trumpTokens[i]]:\n",
    "                #add 1 to the number of occurences\n",
    "                trumpBigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "            #add it to the subdictionary of trump\n",
    "            else:\n",
    "                trumpBigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "                #check bigrams\n",
    "                if trumpTokens[i+1] in bigrams[trumpTokens[i]]:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                else:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "        #the word does not exist yet in trumpBigrams\n",
    "        else:\n",
    "            #initialize a new subdictionary and add the first bigram\n",
    "            trumpBigrams[trumpTokens[i]] = {trumpTokens[i+1]: 1}\n",
    "            #check bigrams\n",
    "            if trumpTokens[i] in bigrams:\n",
    "                #check word\n",
    "                if trumpTokens[i+1] in bigrams[trumpTokens[i]]:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                else:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "            else:\n",
    "                bigrams[trumpTokens[i]] = {trumpTokens[i+1]: 1}\n",
    "    return bigrams, hillBigrams, trumpBigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import float32\n",
    "from math import log, exp\n",
    "\n",
    "'''Need to implement Laplace smoothing'''\n",
    "\n",
    "\n",
    "'''MLE = count of bigram / count of first unigram\n",
    "Laplace: P = (count of bigram + 1)/(count of first unigram + V)\n",
    "where V is the number of possible bigrams given unigram\n",
    "What do we do if the given unigram doesn't exist?'''\n",
    "\n",
    "def smoothProb(word1, word2, sentiment):\n",
    "    P = numpy.float32(0.0)\n",
    "  \n",
    "    #True = hillary\n",
    "    if sentiment == True:\n",
    "        unigramCount = 1\n",
    "        #if the unigram has been seen before\n",
    "        if word1 in hBigrams.keys():\n",
    "            #add one for smoothing\n",
    "            unigramCount = hillTypes[word1] + 1\n",
    "            #if this bigram has been seen before\n",
    "            if word2 in hBigrams[word1].keys():\n",
    "                P = (hBigrams[word1][word2] + 1) / (unigramCount + len(hBigrams[word1]))\n",
    "                #maybe log it? FIGURE OUT LATER\n",
    "            #the second word has not followed the first word before\n",
    "            else:\n",
    "                P = 1 / (unigramCount + len(hBigrams[word1]))\n",
    "        #this unigram has not been seen before\n",
    "        else:\n",
    "            P = unigramCount / (len(hillTokens)+len(hillTypes))\n",
    "        return P\n",
    "    #False = trump\n",
    "    else:\n",
    "        unigramCount = 1\n",
    "        #if the unigram has been seen before\n",
    "        if word1 in tBigrams.keys():\n",
    "            #add one for smoothing\n",
    "            unigramCount = trumpTypes[word1] + 1\n",
    "            #if this bigram has been seen before\n",
    "            if word2 in tBigrams[word1].keys():\n",
    "                P = (tBigrams[word1][word2] + 1) / (unigramCount + len(tBigrams[word1]))\n",
    "                #maybe log it? FIGURE OUT LATER\n",
    "            #the second word has not followed the first word before\n",
    "            else:\n",
    "                P = 1 / (unigramCount + len(tBigrams[word1]))\n",
    "        #this unigram has not been seen before\n",
    "        else:\n",
    "            P = unigramCount / (len(trumpTokens)+len(trumpTypes))\n",
    "        return P\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from math import log, exp\n",
    "'''Need to calculate the following:\n",
    "Classifier:\n",
    "P(s|T) = (P(s)*P(T|s))/P(T)\n",
    "T is the text of the tweet and s is the sentiment\n",
    "\n",
    "P(T|s) = P(G|s) = product(for every g in G)(P(g|s))\n",
    "Where G is the set of n-grams and g is an individual n-gram\n",
    "Calculate P(g|s) using +1 for 0 values\n",
    "\n",
    "Calculate P(T) for all T\n",
    "Then add all g to sets s with counts\n",
    "'''\n",
    "\n",
    "#probS is number of tweets in that sentiment divided by total number of tweets\n",
    "\n",
    "def classify(tweet):\n",
    "    #calculate probT\n",
    "    #probT = 1/(len(hillTweets) + len(trumpTweets))\n",
    "    #probS is number of tweets in that sentiment divided by total number of tweets\n",
    "    probHill = len(hillTweets)/(len(hillTweets) + len(trumpTweets))\n",
    "    probTrump = 1 - probHill\n",
    "    probHillTweet = (probHill * classifyTweet(tweet, True))\n",
    "    probTrumpTweet = (probTrump * classifyTweet(tweet, False))\n",
    "    #return (probHillTweet / (probHillTweet + probTrumpTweet)), (probTrumpTweet / (probHillTweet + probTrumpTweet))\n",
    "    return probHillTweet, probTrumpTweet\n",
    "    \n",
    "def classifyTweet(tweet, sentiment):\n",
    "    tweetTokens = tweet.strip().split(' ')\n",
    "    totalProb = numpy.float32(1.0)\n",
    "    for i in range(0, len(tweetTokens) - 1):\n",
    "        totalProb = totalProb * smoothProb(tweetTokens[i], tweetTokens[i+1], sentiment)\n",
    "    return totalProb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tweet: <start> is right trump would increase debt much more than clinton <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 2.4382861011458234e-21 \n",
      " Donald Trump: 3.288191859403472e-18\n",
      "For tweet: <start> hillary clinton s uninformed know that hillary has taken massive bribes from drugs companies to price gou <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 1.9892802090889415e-31 \n",
      " Donald Trump: 7.63346517053987e-39\n",
      "For tweet: <start> hillary clinton s economic plan would send our economy into a tailspin <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 7.250926362129196e-28 \n",
      " Donald Trump: 2.684467145044163e-24\n",
      "For tweet: <start> do you want a you re hired president in hillary clinton or do you want a you re fired president in donald trump <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.025818251420635e-34 \n",
      " Donald Trump: 1.4571380080893336e-38\n",
      "For tweet: <start> proud of clinton foundation life saving work if only would disclose info about type of work h <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 6.888656740890688e-41 \n",
      " Donald Trump: 2.4449706220306956e-37\n",
      "For tweet: <start> clintons stole 94 of the donations to that country thru the clinton foundation l <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 2.720405272948904e-31 \n",
      " Donald Trump: 1.248818078836586e-35\n",
      "For tweet: <start> pence claimed clinton s plans would raise the debt more than trump s no <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 8.244416233798219e-24 \n",
      " Donald Trump: 4.431773765028152e-25\n",
      "For tweet: <start> if past voting records are fair game how about clinton s previous stances on the iraq war and gay marriage <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.0818616013820808e-40 \n",
      " Donald Trump: 4.502619291263455e-43\n",
      "For tweet: <start> there are 359 000 more black voters in battleground states than in 2012 there are 660 000 more latino voters <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 9.105500185901603e-39 \n",
      " Donald Trump: 1.5782013913401597e-45\n",
      "For tweet: <start> kaine says his family trusts clinton as commander in chief the thought of trump in the role scared us to death <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.512264336368779e-41 \n",
      " Donald Trump: 4.445432742931075e-44\n",
      "For tweet: <start> i ve got a question tim should hillary clinton face consequences for mishandling classified information h <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 1.2810127569536784e-33 \n",
      " Donald Trump: 1.3160727032461878e-36\n",
      "For tweet: <start> hillary clinton s lawlessness and criminality in its enormity makes nixon look like a rookie <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 8.789001651065689e-30 \n",
      " Donald Trump: 9.536840735300257e-33\n",
      "For tweet: <start> i m beginning to believe tim kaine s debate strategy is to make hillary clinton likable compared to him <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 2.7834090297068236e-30 \n",
      " Donald Trump: 3.8091707498431986e-31\n",
      "For tweet: <start> trump in arizona with a new twist to his tax return defense why didn t clinton do more as senator to stop people like me <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.956209356930209e-38 \n",
      " Donald Trump: 1.9485880557793383e-43\n",
      "For tweet: <start> pence referring to my voting record is just another clinton scare tactic <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 9.749552997038624e-08 \n",
      " Donald Trump: 4.264078647176568e-28\n",
      "For tweet: <start> i m beginning to believe tim kaine s debate strategy is to make hillary clinton likable compared to him <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 2.7834090297068236e-30 \n",
      " Donald Trump: 3.8091707498431986e-31\n",
      "For tweet: <start> tim kaine talking over pence just makes him look unlikable just like hillary clinton scum bag characteristics <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 6.820389288304945e-31 \n",
      " Donald Trump: 4.638059372632596e-34\n",
      "For tweet: <start> trump and pence framing the clinton campaign for being one based on scare tactics is the most hypocritical thing i ve ever seen <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 4.0193591145627635e-41 \n",
      " Donald Trump: 9.14588878199453e-50\n",
      "For tweet: <start> question how many private sector jobs has hillary clinton created answer zero except for fbi and doj <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 6.174277523316841e-40 \n",
      " Donald Trump: 4.0470253129764024e-40\n",
      "For tweet: <start> i m so shocked that trump fans think kaine is losing and clinton fans think pence is a dick <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 7.365273067283362e-32 \n",
      " Donald Trump: 4.0134796177090535e-32\n",
      "For tweet: <start> tim kaine talking over pence just makes him look unlikable just like hillary clinton scum bag characteristics <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 6.820389288304945e-31 \n",
      " Donald Trump: 4.638059372632596e-34\n",
      "For tweet: <start> in his first 15 mins pence has hit obamacare coal country clinton foundation national debt syria iraq more tha <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.9023572225292586e-39 \n",
      " Donald Trump: 6.287013245479305e-44\n",
      "For tweet: <start> i wish it were marco rubio jeb bush paul ryan debating hillary clinton we don t always get what we want <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 1.0290462538861402e-41 \n",
      " Donald Trump: 2.292140245747664e-44\n",
      "For tweet: <start> the american people are tired of the spin by clinton kaine re economy truth is millions more in poverty stagnant wages <end> \n",
      "Probability of supporting \n",
      " Hillary Clinton: 3.4431572834541155e-40 \n",
      " Donald Trump: 2.0128239004592955e-44\n",
      "% supporting Hillary Clinton: 0.9999999999662734 \n",
      "% supporting Donald Trump: 3.3726623039671703e-11\n"
     ]
    }
   ],
   "source": [
    "#generate the bigrams dictionary\n",
    "bothBigrams, hBigrams, tBigrams = generateBigramsDict()\n",
    "\n",
    "classify('<start> make america great again <end>')\n",
    "runAnalysis('hillaryTweetsTest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
