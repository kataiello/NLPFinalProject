{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Need to calculate the following:\n",
    "Classifier:\n",
    "P(s|T) = (P(s)*P(T|s))/P(T)\n",
    "T is the text of the tweet and s is the sentiment\n",
    "\n",
    "P(T|s) = P(G|s) = product(for every g in G)(P(g|s))\n",
    "Where G is the set of n-grams and g is an individual n-gram\n",
    "Calculate P(g|s) using +1 for 0 values\n",
    "\n",
    "Calculate P(T) for all T\n",
    "Then add all g to sets s with counts\n",
    "'''\n",
    "\n",
    "\n",
    "#haven't collected corpus yet, assume this will be filled in\n",
    "#LOAD COUNTS OF PROCESSED TWEETS HERE \n",
    "\n",
    "#Load tokens files for bigrams\n",
    "with open('hill_tokens.txt') as f:\n",
    "    hillTokensFile = f.read()\n",
    "    \n",
    "hillTokens = hillTokensFile.strip().split('\\n')\n",
    "\n",
    "with open('trump_tokens.txt') as f:\n",
    "    trumpTokensFile = f.read()\n",
    "    \n",
    "trumpTokens = trumpTokensFile.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9892174006000001, 0.0034346941000000003]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for every word, add it to the dictionary in this format:\n",
    "#key is the word, value is another dictionary\n",
    "    #within each subdictionary, have the following word as the key\n",
    "    #and the number of times it follows as the value\n",
    "\n",
    "#make a bigrams dictionary for both and each candidate\n",
    "bigrams = {}\n",
    "hillBigrams = {}\n",
    "trumpBigrams = {}\n",
    "\n",
    "def generateBigramsDict():\n",
    "    #Add all Hillary positive bigrams to both hillBigrams and bigrams\n",
    "    for i in range(len(hillTokens) - 1):\n",
    "        #if the word already exists\n",
    "        if hillTokens[i] in hillBigrams:\n",
    "            #if the following word already exists\n",
    "            if hillTokens[i+1] in hillBigrams[hillTokens[i]]:\n",
    "                #add 1 to the number of occurences\n",
    "                hillBigrams[hillTokens[i]][hillTokens[i+1]] += 1\n",
    "                bigrams[hillTokens[i]][hillTokens[i+1]] += 1\n",
    "            #add it to the subdictionary of hill\n",
    "            else:\n",
    "                hillBigrams[hillTokens[i]][hillTokens[i+1]] = 1\n",
    "                bigrams[hillTokens[i]][hillTokens[i+1]] = 1\n",
    "        #the word does not exist yet in hillBigrams\n",
    "        else:\n",
    "            #initialize a new subdictionary and add the first bigram\n",
    "            hillBigrams[hillTokens[i]] = {hillTokens[i+1]: 1}\n",
    "            bigrams[hillTokens[i]] = {hillTokens[i+1]: 1}\n",
    "\n",
    "    #Add all Trump positive bigrams to both trumpBigrams and bigrams\n",
    "    for i in range(len(trumpTokens) - 1):\n",
    "        #if the word already exists\n",
    "        if trumpTokens[i] in trumpBigrams:\n",
    "            #if the following word already exists\n",
    "            if trumpTokens[i+1] in trumpBigrams[trumpTokens[i]]:\n",
    "                #add 1 to the number of occurences\n",
    "                trumpBigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "            #add it to the subdictionary of trump\n",
    "            else:\n",
    "                trumpBigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "                #check bigrams\n",
    "                if trumpTokens[i+1] in bigrams[trumpTokens[i]]:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                else:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "        #the word does not exist yet in trumpBigrams\n",
    "        else:\n",
    "            #initialize a new subdictionary and add the first bigram\n",
    "            trumpBigrams[trumpTokens[i]] = {trumpTokens[i+1]: 1}\n",
    "            #check bigrams\n",
    "            if trumpTokens[i] in bigrams:\n",
    "                #check word\n",
    "                if trumpTokens[i+1] in bigrams[trumpTokens[i]]:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] += 1\n",
    "                else:\n",
    "                    bigrams[trumpTokens[i]][trumpTokens[i+1]] = 1\n",
    "            else:\n",
    "                bigrams[trumpTokens[i]] = {trumpTokens[i+1]: 1}\n",
    "            \n",
    "'''Need to implement Good-Turing smoothing'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Need to calculate the following:\n",
    "Classifier:\n",
    "P(s|T) = (P(s)*P(T|s))/P(T)\n",
    "T is the text of the tweet and s is the sentiment\n",
    "\n",
    "P(T|s) = P(G|s) = product(for every g in G)(P(g|s))\n",
    "Where G is the set of n-grams and g is an individual n-gram\n",
    "Calculate P(g|s) using +1 for 0 values\n",
    "\n",
    "Calculate P(T) for all T\n",
    "Then add all g to sets s with counts\n",
    "'''\n",
    "\n",
    "#probS is number of tweets in that sentiment divided by total number of tweets\n",
    "\n",
    "def classify(tweet):\n",
    "    #calculate probT\n",
    "    probT = tweetCount(tweet)/len(tweetCount)\n",
    "    #probS is number of tweets in that sentiment divided by total number of tweets\n",
    "    probS = 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
